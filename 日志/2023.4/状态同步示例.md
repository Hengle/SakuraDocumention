---
create: 2023-04-23 21:40
aliases: []
tags: [ECS, Gameplay, Network]
---
在这个月把搁置许久的状态同步示例完成并上传到了 repo 中。开发这个示例的初衷是研究网络同步的技术细节并探索使用 ECS 实现带有网络同步的 Gameplay 的时候，会有多少网络相关的细节穿透到业务逻辑中（对比实现一个单机的 Gameplay）
不同的需求下有不同的技术细节的选择，本次的示例设定了为一个“强实时，中等规模，基于房间”的目标，对于这个目标，我们至少需要达成如下的技术目标：
* 对象状态同步
* 输入同步
* 数据插值
* 数据压缩
* 画面抽离
* 回滚与重播
下面选一些点分享一下。
## 基本网络库
在网络库的选择上使用了 GameNetworkingSocket，其 API 足够简单，带有内网穿透直连和自定义的基于 UDP 的传输层，比较符合需求。
## 双端的时间同步
时间同步是这个示例中优先级最高的功能，具体来讲就是尝试将所有玩家的游戏时间同步起来，或者至少将玩家和服务器的时间同步起来（因为网络原因，数据的收发存在客观上的延迟）。而达成这个目的的方式就是客户端预测（模拟帧同步的情景）：让客户端和服务器运行完全一致的逻辑，在客户端上预演游戏状态，并在下一次客户端同步的时候验证数据并重新预测。
预演需要考虑三个细节问题：怎么执行相同的代码，预演多少帧，怎么重新预演
第一个问题一般直接采用双端共享代码，也就是将逻辑代码独立出来作为一个单独的模块，客户端和服务器都运行这个模块来进行模拟。模拟采用锁帧的方式进行，将当前状态记录为帧号，两边通过帧号来交流时间信息。
第二个问题通过测量双端的物理延迟来计算，延迟代表了客户端接受到的状态距离服务器当前真实状态的时间差，再加上客户端输入到服务器的时间差，除以帧率即可得到一个帧数差，以让客户端整体领先服务器（至少一帧）。示例中通过一个时间缩放系数对客户端的帧间隔进行缩放，让客户端的更新加速/减速来达成缓慢的增加/减少帧数差，当然在网络剧烈波动的时候还是会产生不平衡的效应。
第三个问题需要实现游戏状态的快照，在适当的时刻进行状态的回滚，这里快照有两种实现形式：
1. 对预测的每一帧都进行快照，当接受到服务器状态的时候，与对应的那一帧的快照进行比对，如果状态一致（误差在可接受范围内），则跳过状态的应用，将这一帧以及之前的快照删除（已经验证过了）
2. 只保留上一次服务器数据的快照（权威数据），当接受服务器状态的时候，丢弃当前状态回滚到服务器数据的快照，应用状态，记录新的快照，重新根据帧数差预测到当前帧
当然两种形式都需要保留每一帧的输入信息，本示例中采用了第二种形式的实现。
最后展示一下流程的伪代码：
```c++
//共享的逻辑
struct GameLogic
{
	//执行一帧的逻辑
	void Tick(GameInput input);
};
//服务器循环
void UpdateServer()
{
	//合并接受到的玩家输入
	ReceiveAndAccumulateInput(input);
	if(FixedUpdate())
	{
		logic.Tick(input);
		//输入被消耗掉了
		ClearInput(input);
		frame++;
	}
	if(ShouldSync())
	{
		SendWorldDeltaToClients(logic);
	}
}
//客户端循环
void UpdateClient()
{
	//应用服务器状态
	if(ReceiveWorldDelta(delta))
	{
		Rollback();
		frame = ApplyWorldDelta(delta);
		//重新预测到当前帧
		while(frame != predictedFrame)
		{
			logic.Tick(predictedInput[frame]);
			currentFrame++;
		}
		//感觉延迟更新时间缩放
		UpdateTimeScale();
	}
	if(ScaledFixedUpdate())
	{
		predictedInput[frame] = input;
		logic.Tick(input);
		frame++;
	}
	SendInputToServer(input);
}
```
## 对象状态同步
本示例中对象状态的收集采用了 pull 的形式，作为对比，push 形式是指对象主动发送需要同步的状态，而本示例是在每帧更新结束之后统一收集所有对象的状态，这种分类也不是绝对的，为了节省性能我们还是采用了脏标记的设计 (需要在对象逻辑中标记）。
示例中的同步的数据组成采用了差异包的形式，既只对从上一次同步到当前时间点（可能）产生了变化的值进行同步，这么做的优点是能大幅压缩需要同步的数据量，而缺点是对丢包和乱序比较敏感，因为增量包必须保序的依次应用。
具体来说，在服务器端，同步相关的组件定义如下：
```c++
sreflect_struct(
    "serialize" : "bin",
    "component" : true
) //对象的数据原型，在服务器和客户端有不同的原型（客户端包含渲染相关的数据）
CPrefab
{
    skr_resource_handle_t prefab;
};

sreflect_struct(
    "component" : 
    {
        "pin" : true
    }
) //维护基础同步信息
CAuth
{
	//是否已经同步给某个客户端
    skr::bitset<128> mappedConnection;
    //是否第一次同步给某个客户端
    skr::bitset<128> initializedConnection;
	//当前已经同步了哪些组件,具体数据在下面的组件里
    dual_type_set_t mappedType;
};

sreflect_struct(
    "component" : 
    {
        "buffer" : 8
    }
) //数组组件，存放已经同步了哪些组件
CAuthTypeData
{
    dual_type_index_t type;
};

sreflect_struct(
    "serialize" : "bin",
    "component" : true
) //相关性组件，控制是否要同步给某个客户端
CRelevance
{
    skr::bitset<128> mask;
};
```
而对应的数据包的结构安排采用了比较“ECS”的方式，数据采用了以每个类型的组件为键的组织形式，而结构变化（entity 的增删，组件的增删等）采用了以 entity 为键。具体的定义如下：
```c++
using NetEntityId = uint16_t;
using NetComponentId = uint8_t;

sreflect_struct("guid": "8F20F35F-38D6-4D2F-AB41-24E582F2378B") 
sattr("blob" : true)
sattr("debug" : true)
MPEntityCreationView
{
    NetEntityId entity;
    skr::span<NetComponentId> components;
    skr_guid_t prefab;
};
GENERATED_BLOB_BUILDER(MPEntityCreationView)

sreflect_struct("guid": "6DEDEB26-1A03-4194-95EF-0E589366C985") 
sattr("blob" : true)
sattr("debug" : true)
MPEntityDeltaView
{
    NetEntityId entity;
    skr::span<NetComponentId> components;
    skr::span<NetComponentId> deleted;
};
GENERATED_BLOB_BUILDER(MPEntityDeltaView)

sreflect_struct("guid": "B2A257E7-E153-485E-A4B5-5D0B2EC65E42")  
sattr("blob" : true)
sattr("debug" : true)
MPComponentDeltaView
{
    NetComponentId type;
    skr::span<NetEntityId> entities;
    sattr("no-text" : true)
    skr::span<uint8_t> data;
};
GENERATED_BLOB_BUILDER(MPComponentDeltaView)


sreflect_struct("guid": "0E7D9309-13EF-4EB8-9E8E-2DDE8D8F7BA0") 
sattr("blob" : true)
sattr("debug" : true)
MPWorldDeltaView
{
	//所有对象的id
    skr::span<dual_entity_t> entities; 
    //变化的组件和数据
    skr::span<MPComponentDeltaView> components;
    //创建的对象
    skr::span<MPEntityCreationView> created;
    //变化的组件
    skr::span<MPEntityDeltaView> changed;
    //删除的对象
    skr::span<NetEntityId> dead;
};
GENERATED_BLOB_BUILDER(MPWorldDeltaView)

sreflect_struct("guid": "54C41BFD-130C-4AF6-AD50-F43D5C6E8AE5")
sattr("serialize" : "bin")
MPWorldDelta
{
    uint64_t frame;
    skr_blob_arena_t arena; 
    spush_attr("arena" : "arena")
    MPWorldDeltaView blob;
}; 
```
可以看到数据包由大量的变长数据段组成，为了节省性能我们采用了 [[序列化相关#Blob|Blob]] 技术对数据包的构建和读取进行了分离，使得读取数据时不再需要分配内存。
有了数据结构，接下来就是构建这个数据，收集的整体流程分为两步：
1. 单线程 - 收集创建的对象和，并同时收集每个组件需要同步的对象（变化的）
2. 多线程 - 对每个组件进行具体的数据收集（序列化）
具体的代码可以在 [repo](https://github.com/SakuraEngine/SakuraEngine/tree/GUI) 中查看。
## 数据的压缩
在使用之前写的序列化功能完成了组件序列化后，流量的使用远远超过了预期。于是需要考虑对数据进行压缩，展开来说，数据压缩一般有这些方式：
* 通用压缩算法，对信息直接进行压缩
* 去除不需要同步的数据
* 删减需要同步的数据中的无效部分
	* 有损的去除一些精度
	* 无损的去除空白的部分，也就是位打包
对于通用压缩算法，示例中尝试使用了 LZ4 进行数据的压缩，实际测试下来表现并不好，压缩率只有 10% 左右
去除不需要同步的数据和减少精度都是和业务相关的压缩方案，通过编码人员对需求认知的信息来进行数据的压缩。
对于位打包，现在引擎中的序列化器添加了按位序列化的接口并提供了一个默认的位压缩序列化器实现。为基础类型扩展了一些带有压缩选项的版本，用户类的代码生成中也加入了自定义压缩的选项。下面是一段示例代码展示了使用历史同步数据和位打包来压缩位置信息的同步：
```c++
static skr::binary::VectorSerdeConfig<float> translationSerdeConfig = { 10000 };
constexpr auto builder = +[](dual_chunk_view_t view, const skr_translation_comp_t& comp, skr_translation_comp_t_History& historyComp, bool initialMap, skr_binary_writer_t& archive)
{
	uint32_t full = initialMap || historyComp.deltaAccumulated > 40.f;
	skr_float2_t delta;
	delta.x = comp.value.x - historyComp.position.x;
	delta.y = comp.value.z - historyComp.position.y;
	if(!initialMap && (std::abs(delta.x) < 0.0001f && std::abs(delta.y) < 0.0001f))
		//skip if not moving
		return true;
	archive.write_bits(&full, 1);
	if(full)
	{
		skr::binary::Archive(&archive, comp.value, translationSerdeConfig);
		historyComp.position.x = comp.value.x;
		historyComp.position.y = comp.value.z;
		historyComp.deltaAccumulated = 0.f;
	}
	else
	{
		skr::binary::Archive(&archive, delta, translationSerdeConfig);
		historyComp.position.x = comp.value.x;
		historyComp.position.y = comp.value.z;
		historyComp.deltaAccumulated += std::abs(delta.x) + std::abs(delta.y);
	}
	return false;
};
```
通过实践这些技巧，最终将数据压缩到了原流量的 1/3
## 分离
因为客户端的逻辑需要和服务器同步，整个逻辑世界是共享的，虽然 ECS 下可以做到增加在客户端给对象附加额外的数据和逻辑同时不影响逻辑世界，但是锁定的帧率是没法改变的。并且当因为网络波动位置闪烁的时候，我们也需要进行一些平滑的处理。
为了解决这些问题可以将逻辑和表现分离为两个世界，并在两个世界之间进行同步，这里的“世界”不一定对应引擎中的世界，事实上只是需要把数据进行分离，比如位移（translation）分离为渲染位移和逻辑位移，要做到这一点有很多做法，比如直接分离为两个组件，挂在同一个 entity 上面或分离为两个 entity。
在示例中展示了分离为两个 entity 的做法，选择这种做法的原因是数据驱动倾向于将数据按索引的频率来进行存放，显然渲染 entity 的索引频率（60/120 fps）于逻辑 entity 的（20/30/60 fps）并不一致。
## 结论
回到一开始的问题：“实现带有网络同步的 Gameplay 的时候，会有多少网络相关的细节穿透到业务逻辑中。“，对于状态同步而言，答案是：
* 压缩流量需要人工参与
	* 业务代码中手动标记脏数据（或者付出少许性能代价 Hook 所有的写入点）
	* 手动实现序列化函数以控制同步精度
* 拆分逻辑层和表现层会使表现相关的代码会更复杂，当然也可以不拆分（提高服务器帧率）
总的来说，大部分的网络细节确实可以封装到框架之内。
